{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0429660-dabc-4c9b-a334-a7b59b420e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from overfero.data_modules.data_modules import TextClassificationDataModule\n",
    "from overfero.models.transformations import HuggingFaceTokenizationTransformation\n",
    "import tensorflow as tf\n",
    "from overfero.models.models import BinaryTextClassificationModel\n",
    "from overfero.models.backbones import HuggingFaceBackbone\n",
    "from overfero.models.adapters import DenseAdapter\n",
    "from overfero.models.heads import SigmoidHead\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43804579-a5e0-4f94-820c-1a3cc09bb523",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = HuggingFaceTokenizationTransformation(\n",
    "    pretrained_tokenizer_name_or_path=\"trained_tokenizer\",\n",
    "    max_sequence_length=128,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4194739-b92d-4214-bb8e-2d02c8421404",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modules = TextClassificationDataModule(\n",
    "    \"data/processed/train.parquet\",\n",
    "    \"data/processed/dev.parquet\",\n",
    "    \"data/processed/test.parquet\",\n",
    "    transformation,\n",
    "    \"cleaned_text\",\n",
    "    \"label\",\n",
    "    32,\n",
    "    True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8d3acb7-28b4-4e35-8c6f-92f8ad958d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_modules.setup(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3b9673b-e1f1-4250-a0e4-0d18cf05065d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data_modules.initialize_dataloader(data_modules.test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "710eb56a-de58-44df-ac5b-48c91dc8539c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wwwyoutubecomwatch vkacwpkaktak a talk natural...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>very nice i tend get tired constant stream rid...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>watch today circumcision viacom</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thinking venues first color layer blocking fig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what death penalty perpetrators expelling rema...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33930</th>\n",
       "      <td>that game nuts as kid i dropped copy save corr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39433</th>\n",
       "      <td>and that leave could instead pin first tweet f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26695</th>\n",
       "      <td>the head call yesterday bully ask till saliva ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36871</th>\n",
       "      <td>people bagging tall girl movie look see bullyi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16396</th>\n",
       "      <td>but islam rape captive women hearts content law</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16792 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            cleaned_text  label\n",
       "0      wwwyoutubecomwatch vkacwpkaktak a talk natural...      0\n",
       "1      very nice i tend get tired constant stream rid...      0\n",
       "2                        watch today circumcision viacom      0\n",
       "3      thinking venues first color layer blocking fig...      0\n",
       "4      what death penalty perpetrators expelling rema...      0\n",
       "...                                                  ...    ...\n",
       "33930  that game nuts as kid i dropped copy save corr...      1\n",
       "39433  and that leave could instead pin first tweet f...      1\n",
       "26695  the head call yesterday bully ask till saliva ...      1\n",
       "36871  people bagging tall girl movie look see bullyi...      1\n",
       "16396    but islam rape captive women hearts content law      1\n",
       "\n",
       "[16792 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_modules.test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2031a75-b28c-441e-b10d-f874021fbcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(32, 126), dtype=int32, numpy=\n",
      "array([[ 3467,  1461,  1774, ...,     3,     3,     3],\n",
      "       [  802,   347,   223, ...,     3,     3,     3],\n",
      "       [ 5888,   309,   639, ...,     3,     3,     3],\n",
      "       ...,\n",
      "       [  893,  1015,  4806, ...,     3,     3,     3],\n",
      "       [  241,  1123, 11502, ...,     3,     3,     3],\n",
      "       [  971, 25980,  1220, ...,     3,     3,     3]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(32, 126), dtype=int32, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 126), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>} \n",
      "\n",
      " tf.Tensor([0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 1 0 0 0 1 0 0 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "inp, out = next(iter(dataset)) # a batch from train_dataset\n",
    "print(inp, '\\n\\n', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82fdfd09-f959-4014-bb19-9b8e6d68729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = HuggingFaceBackbone(\"prajjwal1/bert-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0016166a-7b2a-4469-b124-d0f1e63098bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adapter = DenseAdapter(256,\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74f1fc58-a488-4c26-b8a5-f0ea6cb822f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "head = SigmoidHead()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68558f29-2f5d-4147-9500-f546513661d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryTextClassificationModel(backbone, adapter, head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50732874-5050-4d5a-a482-6d88e21b3e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=BinaryCrossentropy(), optimizer=Adam(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d02a617-5aec-41e9-9217-338e4b57e189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"binary_text_classification_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"binary_text_classification_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hugging_face_backbone           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">HuggingFaceBackbone</span>)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_adapter (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DenseAdapter</span>)    │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sigmoid_head (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SigmoidHead</span>)      │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hugging_face_backbone           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mHuggingFaceBackbone\u001b[0m)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_adapter (\u001b[38;5;33mDenseAdapter\u001b[0m)    │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ sigmoid_head (\u001b[38;5;33mSigmoidHead\u001b[0m)      │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c3be276-e035-454b-806c-9ed90bdfd91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 15:18:43.859118: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 15627264 exceeds 10% of free system memory.\n",
      "2024-04-09 15:18:43.901353: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 15627264 exceeds 10% of free system memory.\n",
      "2024-04-09 15:18:44.036030: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 15627264 exceeds 10% of free system memory.\n",
      "/home/overfero/venv/lib/python3.10/site-packages/keras/src/layers/layer.py:1248: UserWarning: Layer 'binary_text_classification_model' looks like it has unbuilt state, but Keras is not able to trace the layer `call()` in order to build it automatically. Possible causes:\n",
      "1. The `call()` method of your layer may be crashing. Try to `__call__()` the layer eagerly on some test input first to see if it works. E.g. `x = np.random.random((3, 4)); y = layer(x)`\n",
      "2. If the `call()` method is correct, then you may need to implement the `def build(self, input_shape)` method on your layer. It should create all variables used by the layer (e.g. by calling `layer.build()` on all its children layers).\n",
      "Exception encountered: ''Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor 'hugging_face_backbone_1/tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/batchnorm/add_1:0' shape=(None, 126, 128) dtype=float32>, pooler_output=<tf.Tensor 'hugging_face_backbone_1/tf_bert_model/bert/pooler/dense/Tanh:0' shape=(None, 128) dtype=float32>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None) (of type <class 'transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions'>)''\n",
      "  warnings.warn(\n",
      "/home/overfero/venv/lib/python3.10/site-packages/keras/src/layers/layer.py:357: UserWarning: `build()` was called on layer 'binary_text_classification_model', however the layer does not have a `build()` method implemented and it looks like it has unbuilt state. This will cause the layer to be marked as built, despite not being actually built, which may cause failures down the line. Make sure to implement a proper `build()` method.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling BinaryTextClassificationModel.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor 'binary_text_classification_model_1/hugging_face_backbone_1/tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/batchnorm/add_1:0' shape=(None, 126, 128) dtype=float32>, pooler_output=<tf.Tensor 'binary_text_classification_model_1/hugging_face_backbone_1/tf_bert_model/bert/pooler/dense/Tanh:0' shape=(None, 128) dtype=float32>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None) (of type <class 'transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions'>)\u001b[0m\n\nArguments received by BinaryTextClassificationModel.call():\n  • x={'input_ids': 'tf.Tensor(shape=(None, 126), dtype=int32)', 'token_type_ids': 'tf.Tensor(shape=(None, 126), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(None, 126), dtype=int32)'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/venv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/app/overfero/models/models.py:24\u001b[0m, in \u001b[0;36mBinaryTextClassificationModel.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     23\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x)\n\u001b[0;32m---> 24\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling BinaryTextClassificationModel.call().\n\n\u001b[1mOnly input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor 'binary_text_classification_model_1/hugging_face_backbone_1/tf_bert_model/bert/encoder/layer_._1/output/LayerNorm/batchnorm/add_1:0' shape=(None, 126, 128) dtype=float32>, pooler_output=<tf.Tensor 'binary_text_classification_model_1/hugging_face_backbone_1/tf_bert_model/bert/pooler/dense/Tanh:0' shape=(None, 128) dtype=float32>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None) (of type <class 'transformers.modeling_tf_outputs.TFBaseModelOutputWithPoolingAndCrossAttentions'>)\u001b[0m\n\nArguments received by BinaryTextClassificationModel.call():\n  • x={'input_ids': 'tf.Tensor(shape=(None, 126), dtype=int32)', 'token_type_ids': 'tf.Tensor(shape=(None, 126), dtype=int32)', 'attention_mask': 'tf.Tensor(shape=(None, 126), dtype=int32)'}"
     ]
    }
   ],
   "source": [
    "model.fit(dataset, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63e602e4-5073-4b18-ac9c-dfa74d0b0593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=({'input_ids': TensorSpec(shape=(None, 126), dtype=tf.int32, name=None), 'token_type_ids': TensorSpec(shape=(None, 126), dtype=tf.int32, name=None), 'attention_mask': TensorSpec(shape=(None, 126), dtype=tf.int32, name=None)}, TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1563ddd-07dd-40a3-9b32-3bfac90b8aae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8b7d6879-bb4d-4df1-af82-e40f512289f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd62ef27-65b6-4591-a9f8-efc6461e4a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_parquet(\"data/processed/test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db3e248f-22ab-44b2-baa9-9e336f233957",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset[[\"cleaned_text\", \"label\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "bb34b5bc-5ba0-448b-a0ea-05e1256ae2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(texts):\n",
    "    encodings = transformation(texts.to_list())\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6a6546f9-20df-47af-b599-ff5c9d89565a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = collate_fn(train_dataset[\"cleaned_text\"][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bac64592-f96f-4c19-8189-631d4c67c7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(100, 50), dtype=int32, numpy=\n",
       "array([[ 3252,    27,    16, ...,     3,     3,     3],\n",
       "       [ 2013,  1127,    14, ...,     3,     3,     3],\n",
       "       [  860,  1149,  7296, ...,     3,     3,     3],\n",
       "       ...,\n",
       "       [   32,   366,   639, ...,     3,     3,     3],\n",
       "       [ 2737,  5349,  1595, ...,     3,     3,     3],\n",
       "       [ 1467, 12621,   456, ...,     3,     3,     3]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(100, 50), dtype=int32, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(100, 50), dtype=int32, numpy=\n",
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3895f829-2943-4465-b829-c835721f1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_input_ids = tf.data.Dataset.from_tensor_slices(train_encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "23c33f08-3bc3-4424-b30e-36dc12ab5e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_attention_mask = tf.data.Dataset.from_tensor_slices(train_encodings.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5b87b6db-0c79-4570-82da-c183d2f5960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tf.data.Dataset.from_tensor_slices(dict(train_encodings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8e6e339b-e19a-47da-afb3-0e89c9b965c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = tf.data.Dataset.from_tensor_slices(train_dataset.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1064919e-27d7-4967-9061-34ba57f54e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.zip(train_encodings, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d0b3f73d-c04e-43e5-8f53-91399ecea976",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.shuffle(buffer_size=2000).batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "59ccb8c3-82a5-4717-935e-669a7132be7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor: shape=(32, 50), dtype=int32, numpy=\n",
      "array([[ 1947, 10971,   363, ...,     3,     3,     3],\n",
      "       [  399,   617,    14, ...,     3,     3,     3],\n",
      "       [10499, 20622,   147, ...,     3,     3,     3],\n",
      "       ...,\n",
      "       [   46,    46,   981, ...,     3,     3,     3],\n",
      "       [    6,   402,  1051, ...,     3,     3,     3],\n",
      "       [  420,  3175, 10035, ...,     3,     3,     3]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(32, 50), dtype=int32, numpy=\n",
      "array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(32, 50), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>} \n",
      "\n",
      " tf.Tensor([0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0], shape=(32,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "inp, out = next(iter(train_dataset)) # a batch from train_dataset\n",
    "print(inp, '\\n\\n', out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9390ce2b-acf3-4250-80ee-51b91e6b44d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score\n",
    "from overfero.models.backbones import HuggingFaceBackbone\n",
    "from tensorflow.keras import Model\n",
    "# from transformers import AutoConfig, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5bd48247-65cb-4bb6-b17c-4a0ce11585b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone = HuggingFaceBackbone(\"prajjwal1/bert-tiny\", transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8567088b-0b5f-460f-95c4-4772243550c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTForClassification(Model):\n",
    "    \n",
    "    def __init__(self, bert_model):\n",
    "        super().__init__()\n",
    "        self.bert = bert_model\n",
    "        self.dense1 = Dense(256, \"relu\")\n",
    "        self.dense2 = Dense(64, \"relu\")\n",
    "        self.dense3 = Dense(16, \"relu\")\n",
    "        self.outputs = Dense(1, \"sigmoid\")\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.bert(inputs)[1]\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return self.outputs(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1760b32a-3044-4957-af76-5507cd69d1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTForClassification(backbone)\n",
    "model.compile(loss=BinaryCrossentropy(), optimizer=Adam(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1bc779c9-4ba0-4a96-8be6-c745e130a549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"bert_for_classification\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"bert_for_classification\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hugging_face_backbone_2         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">HuggingFaceBackbone</span>)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ hugging_face_backbone_2         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mHuggingFaceBackbone\u001b[0m)           │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "4ec5116f-bf25-4af5-a2df-66d1e226f763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 109ms/step - accuracy: 0.5904 - loss: 0.6888\n",
      "Epoch 2/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8614 - loss: 0.6029 \n",
      "Epoch 3/3\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8885 - loss: 0.5418\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1d5a6c7c-ae39-47a1-b3f8-4815ac021641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54abfda0-dcf5-41cd-970d-9b09cc624ed8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
